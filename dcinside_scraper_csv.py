import requests
import trafilatura
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
import csv

# -----------------------------------------
# 1. ê²Œì‹œê¸€ ë²ˆí˜¸ ìˆ˜ì§‘ (trafilatura ì‚¬ìš©)
# -----------------------------------------

def get_post_numbers_with_trafilatura(gallery_id='onshinproject'):
    url = f'https://gall.dcinside.com/mgallery/board/lists/?id={gallery_id}&exception_mode=recommend'
    downloaded = trafilatura.fetch_url(url)
    
    if downloaded:
        soup = BeautifulSoup(downloaded, 'html.parser')
        post_list = soup.select('tr.ub-content[data-no]')
        return [tr['data-no'] for tr in post_list if tr.has_attr('data-no')]
    else:
        print("íŠ¸ë¼í•„ë¼íˆ¬ë¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return []

# -----------------------------------------
# 2. ë³¸ë¬¸ + ëŒ“ê¸€ ìˆ˜ì§‘ (Selenium ì‚¬ìš©)
# -----------------------------------------

def scrape_post_content_and_comments(post_number, gallery_id='onshinproject'):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("user-agent=Mozilla/5.0")

    driver = webdriver.Chrome(options=options)

    url = f'https://gall.dcinside.com/mgallery/board/view/?id={gallery_id}&no={post_number}&exception_mode=recommend'
    driver.get(url)
    time.sleep(2)

    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # ì œëª©
    title_tag = soup.select_one('span.title_subject')
    title_text = title_tag.get_text(strip=True) if title_tag else "[ì œëª© ì—†ìŒ]"

    # ë³¸ë¬¸
    content_area = soup.select_one('div.write_div')
    content_text = content_area.get_text(strip=True) if content_area else "[ë³¸ë¬¸ ì—†ìŒ]"

    # ëŒ“ê¸€
    comments = []
    comment_items = soup.select('ul.cmt_list > li.ub-content')
    for li in comment_items:
        text_tag = li.select_one('.usertxt')
        if text_tag:
            comment = text_tag.get_text(strip=True)
            comments.append(comment)

    driver.quit()
    return title_text, content_text, comments

# -----------------------------------------
# 3. ì‹¤í–‰ ë¡œì§ + CSV ì €ì¥
# -----------------------------------------

if __name__ == "__main__":
    gallery_id = 'onshinproject'
    post_numbers = get_post_numbers_with_trafilatura(gallery_id)

    print(f"âœ… ì¶”ì²œ ê²Œì‹œê¸€ {len(post_numbers)}ê°œ ìˆ˜ì§‘ë¨\n")

    # CSV íŒŒì¼ ì—´ê¸°
    with open('dcinside_posts.csv', 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['ê²Œì‹œë²ˆí˜¸', 'ì œëª©', 'ë³¸ë¬¸ë‚´ìš©', 'ëŒ“ê¸€ë‚´ìš©'])  # í—¤ë”

        for i, post_no in enumerate(post_numbers, 1):
            print(f"ğŸ“¥ ({i}/{len(post_numbers)}) ê²Œì‹œê¸€ ë²ˆí˜¸: {post_no}")
            try:
                title, content, comments = scrape_post_content_and_comments(post_no, gallery_id)
                comment_text = " || ".join(comments) if comments else "[ëŒ“ê¸€ ì—†ìŒ]"
                writer.writerow([post_no, title, content, comment_text])
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ (ê²Œì‹œê¸€ ë²ˆí˜¸ {post_no}): {e}")
