import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib
matplotlib.rc('font', family='Malgun Gothic')  # ìœˆë„ìš°ì˜ ê¸°ë³¸ í•œê¸€ í°íŠ¸
plt.rcParams['axes.unicode_minus'] = False     # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
df_56 = pd.read_csv('genshin_5.6.csv')
df_57 = pd.read_csv('genshin_5.7.csv')

# ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •: 'body' â†’ 'content', 'comment' â†’ 'comments'
df_56['text'] = df_56['title'].fillna('') + ' ' + df_56['content'].fillna('') + ' ' + df_56['comments'].fillna('')
df_57['text'] = df_57['title'].fillna('') + ' ' + df_57['content'].fillna('') + ' ' + df_57['comments'].fillna('')

# 2. ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë”©
model_name = "slave-factory/kobert-emotion-classifier-v3"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
classifier = pipeline("text-classification", model=model, tokenizer=tokenizer, top_k=None)

def analyze_emotion(text):
    try:
        result = classifier(text[:512])[0]  # ê¸´ í…ìŠ¤íŠ¸ ìë¥´ê¸°
        return pd.Series([result['label'], result['score']])
    except Exception:
        return pd.Series(['error', 0])

# 3. ê°ì •ë¶„ì„ ì ìš©
# df_56[['label', 'score']] = df_56['text'].apply(analyze_emotion)
# df_57[['label', 'score']] = df_57['text'].apply(analyze_emotion)
# 3. ê°ì •ë¶„ì„ ì ìš© (title ê¸°ì¤€ë§Œ ì‚¬ìš©)
def analyze_emotion_title_only(title):
    try:
        result = classifier(title[:512])[0]
        return pd.Series([result['label'], round(result['score'], 4)])
    except Exception:
        return pd.Series(['error', 0])

df_56[['label', 'score']] = df_56['title'].fillna('').apply(analyze_emotion_title_only)
df_57[['label', 'score']] = df_57['title'].fillna('').apply(analyze_emotion_title_only)


# 4. TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_top_keywords(texts, top_n=10):
    vectorizer = TfidfVectorizer(max_features=500)
    tfidf_matrix = vectorizer.fit_transform(texts)
    scores = tfidf_matrix.sum(axis=0).A1
    keywords = [word for word, idx in sorted(vectorizer.vocabulary_.items(), key=lambda x: -scores[x[1]])[:top_n]]
    return keywords

keywords_56 = extract_top_keywords(df_56['text'])
keywords_57 = extract_top_keywords(df_57['text'])

print("ğŸ” 5.6 í‚¤ì›Œë“œ:", keywords_56)
print("ğŸ” 5.7 í‚¤ì›Œë“œ:", keywords_57)

# 5. ê°ì • ë¶„í¬ ì‹œê°í™” ì €ì¥
def plot_emotion_distribution(df, title, filename):
    sns.countplot(data=df, x='label')
    plt.title(title)
    plt.savefig(filename)
    plt.clf()

plot_emotion_distribution(df_56, "5.6 ê°ì • ë¶„í¬", "emotion_56.png")
plot_emotion_distribution(df_57, "5.7 ê°ì • ë¶„í¬", "emotion_57.png")

# 6. ê²°ê³¼ ì €ì¥
df_56.to_csv("result_5_6.csv", index=False)
df_57.to_csv("result_5_7.csv", index=False)

print("âœ… ê°ì •ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ê°€ result_5_6.csv, result_5_7.csv ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
