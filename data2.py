from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time
import csv

# 1. í¬ë¡¬ ì˜µì…˜ ì„¤ì •
options = Options()
options.add_argument("--headless")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("user-agent=Mozilla/5.0")

# 2. ë“œë¼ì´ë²„ ì‹¤í–‰
driver = webdriver.Chrome(options=options)

# 3. í¬ë¡¤ë§í•  ëª©ë¡ í˜ì´ì§€ URL
base_url = "https://gall.dcinside.com/mgallery/board/lists/?id=onshinproject&page=2&exception_mode=recommend"
start_page = 37
num_posts_to_scrape = 100
post_links = []

# 4. ëª©ë¡ì—ì„œ ì œëª© + ë§í¬ ìˆ˜ì§‘
while len(post_links) < num_posts_to_scrape:
    driver.get(base_url + str(start_page))
    time.sleep(2)
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    rows = soup.select('tbody > tr.ub-content')
    
    for row in rows:
        a_tag = row.select_one('td.gall_tit > a[href]')
        if a_tag and 'view' in a_tag['href']:
            link = "https://gall.dcinside.com" + a_tag['href']
            title = a_tag.text.strip()
            post_links.append({
                'title': title,
                'url': link
            })
            if len(post_links) >= num_posts_to_scrape:
                break
    start_page += 1

print(f"âœ… {len(post_links)}ê°œì˜ ê²Œì‹œê¸€ ì œëª©+ë§í¬ ìˆ˜ì§‘ ì™„ë£Œ")

# 5. ê²Œì‹œê¸€ ë³¸ë¬¸+ëŒ“ê¸€ ìˆ˜ì§‘
results = []

for idx, post in enumerate(post_links):
    url = post['url']
    title = post['title']
    
    driver.get(url)
    time.sleep(1)
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # ë³¸ë¬¸
    content_area = soup.select_one('div.write_div')
    content_text = content_area.get_text(strip=True) if content_area else "[ë³¸ë¬¸ ì—†ìŒ]"

    # ëŒ“ê¸€
    comments = []
    comment_items = soup.select('ul.cmt_list > li.ub-content')
    for li in comment_items:
        text_tag = li.select_one('.usertxt')
        if text_tag:
            comments.append(text_tag.get_text(strip=True))
    
    results.append({
        'title': title,
        'content': content_text,
        'comments': " | ".join(comments) if comments else "[ëŒ“ê¸€ ì—†ìŒ]"
    })

    print(f"ğŸ“„ ({idx+1}) {title[:30]}... ìˆ˜ì§‘ ì™„ë£Œ")

# 6. CSV ì €ì¥
csv_filename = "ì›ì‹ _5.7_ìœ ì €ë°˜ì‘_í¬ë¡¤ë§.csv"
with open(csv_filename, mode='w', encoding='utf-8-sig', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=['title', 'content', 'comments'])
    writer.writeheader()
    for item in results:
        writer.writerow(item)

print(f"\nâœ… CSV ì €ì¥ ì™„ë£Œ: {csv_filename}")

# ë“œë¼ì´ë²„ ì¢…ë£Œ
driver.quit()